{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOoWzzWdyfB+lXYs2SXhofq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uday1277/red-wine/blob/main/Copy_of_wine_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE3dPNn6fsXi",
        "outputId": "1786668d-0615-407d-b4cc-fe7198cdbf56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting data\n",
            "  Downloading data-0.4.tar.gz (7.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from data) (1.16.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from data) (4.4.2)\n",
            "Collecting funcsigs (from data)\n",
            "  Downloading funcsigs-1.0.2-py2.py3-none-any.whl (17 kB)\n",
            "Building wheels for collected packages: data\n",
            "  Building wheel for data (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for data: filename=data-0.4-py3-none-any.whl size=7227 sha256=ae0d0530c1e5def7d7657461c256ddf0890cc42655350d5e48c4fca4d74d86d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/e8/fa/e253c256048ea58d99a8abb5e751abb6a838af6f12887b5418\n",
            "Successfully built data\n",
            "Installing collected packages: funcsigs, data\n",
            "Successfully installed data-0.4 funcsigs-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install MessagePassing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3iyAhf0f0rE",
        "outputId": "59bf45da-2336-47fc-844a-aebeac7a8d5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement MessagePassing (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for MessagePassing\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install add_self_loops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMsmipH5f_EZ",
        "outputId": "9d3ab361-dd0b-4909-83c3-4a4a69baec3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement add_self_loops (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for add_self_loops\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric.nn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SF4LH_1HgCoI",
        "outputId": "dcf636d8-1978-4423-a1ad-d42ada3bcfc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch_geometric.nn (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch_geometric.nn\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-geometric\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rpt9LK0XlI1O",
        "outputId": "2a2617ce-273e-40ea-b23e-b8b4b12a4525"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pDoJmeJlPKp",
        "outputId": "b22e1ebc-5cf6-4703-b658-4045b34663cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Try to read the CSV file\n",
        "try:\n",
        "    df = pd.read_csv(\"dataset.csv\", encoding='latin1')\n",
        "    print(\"CSV file read successfully.\")\n",
        "except pd.errors.ParserError as e:\n",
        "    print(f\"Error reading CSV file: {e}\")\n",
        "    # Handle the error or exit the script\n",
        "\n",
        "# Assuming 'quality' is the target variable\n",
        "# Map target variable to start from 0\n",
        "y_mapping = {label: idx for idx, label in enumerate(sorted(df['quality'].unique()))}\n",
        "df['quality'] = df['quality'].map(y_mapping)\n",
        "\n",
        "# Split the data into features (X) and target variable (y)\n",
        "X = df.drop('quality', axis=1)\n",
        "y = df['quality']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=7)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Create a Decision Tree model\n",
        "model = DecisionTreeClassifier(random_state=7)\n",
        "\n",
        "# Fit the model to the training data\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Reverse map predicted values to original labels\n",
        "y_pred_original = pd.Series(y_pred).map({v: k for k, v in y_mapping.items()})\n",
        "\n",
        "# Print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred_original)\n",
        "print(f\"Accuracy Percentage: {accuracy * 100}\\n\\n\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEgEPYcLsw46",
        "outputId": "d3904b20-692b-450b-cb24-1b21101b01fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading CSV file: Error tokenizing data. C error: Expected 1 fields in line 4, saw 3\n",
            "\n",
            "Accuracy Percentage: 59.166666666666664\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "from torch_geometric.nn import ChebConv\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Try to read the CSV file\n",
        "try:\n",
        "    df = pd.read_csv(\"dataset.csv\", encoding='latin1')\n",
        "    print(\"CSV file read successfully.\")\n",
        "except pd.errors.ParserError as e:\n",
        "    print(f\"Error reading CSV file: {e}\")\n",
        "    # Handle the error or exit the script\n",
        "\n",
        "# Assuming 'quality' is the target variable\n",
        "# Map target variable to start from 0\n",
        "y_mapping = {label: idx for idx, label in enumerate(sorted(df['quality'].unique()))}\n",
        "df['quality'] = df['quality'].map(y_mapping)\n",
        "\n",
        "# Split the data into features (X) and target variable (y)\n",
        "X = df.drop('quality', axis=1)\n",
        "y = df['quality']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=7)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "x_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
        "x_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float)\n",
        "\n",
        "# Create a graph data structure using PyTorch Geometric\n",
        "num_nodes = X_train_scaled.shape[0]\n",
        "edge_index = torch.tensor([[i, i] for i in range(num_nodes)], dtype=torch.long).t().contiguous()\n",
        "\n",
        "# Define an improved Graph Convolutional Network (GCN) model\n",
        "class ImprovedGNNModel(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels1, hidden_channels2, out_channels, dropout_rate=0.5):\n",
        "        super(ImprovedGNNModel, self).__init__()\n",
        "        self.conv1 = ChebConv(in_channels, hidden_channels1, K=2)\n",
        "        self.conv2 = ChebConv(hidden_channels1, hidden_channels2, K=2)\n",
        "        self.conv3 = ChebConv(hidden_channels2, out_channels, K=2)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.conv3(x, edge_index))\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# Initialize and train the improved GNN model\n",
        "improved_model = ImprovedGNNModel(\n",
        "    in_channels=X_train_scaled.shape[1],\n",
        "    hidden_channels1=64,\n",
        "    hidden_channels2=32,\n",
        "    out_channels=len(y_mapping),\n",
        "    dropout_rate=0.5\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.Adam(improved_model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Convert data to PyTorch Geometric Data object\n",
        "data = Data(x=x_train_tensor, edge_index=edge_index, y=y_train_tensor)\n",
        "loader = DataLoader([data], batch_size=1, shuffle=True)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(200):\n",
        "    improved_model.train()\n",
        "    for batch in loader:\n",
        "        optimizer.zero_grad()\n",
        "        out = improved_model(batch)\n",
        "        loss = criterion(out, batch.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Evaluate the improved GNN model on the test set\n",
        "improved_model.eval()\n",
        "with torch.no_grad():\n",
        "    test_data = Data(x=x_test_tensor, edge_index=edge_index)\n",
        "    out = improved_model(test_data)\n",
        "    y_pred = out.argmax(dim=1).numpy()\n",
        "\n",
        "# Reverse map predicted values to original labels\n",
        "y_pred_original = pd.Series(y_pred).map({v: k for k, v in y_mapping.items()})\n",
        "\n",
        "# Print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred_original)\n",
        "print(f\"Accuracy Percentage: {accuracy * 100}\\n\\n\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_biGfKF4t1kj",
        "outputId": "d4c08fe6-7297-40ca-b497-440e78aba164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading CSV file: Error tokenizing data. C error: Expected 1 fields in line 4, saw 3\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Percentage: 61.04166666666667\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Try to read the CSV file\n",
        "try:\n",
        "    df = pd.read_csv(\"dataset.csv\", encoding='latin1')\n",
        "    print(\"CSV file read successfully.\")\n",
        "except pd.errors.ParserError as e:\n",
        "    print(f\"Error reading CSV file: {e}\")\n",
        "    # Handle the error or exit the script\n",
        "\n",
        "# Assuming 'quality' is the target variable\n",
        "# Map target variable to start from 0\n",
        "y_mapping = {label: idx for idx, label in enumerate(sorted(df['quality'].unique()))}\n",
        "df['quality'] = df['quality'].map(y_mapping)\n",
        "\n",
        "# Split the data into features (X) and target variable (y)\n",
        "X = df.drop('quality', axis=1)\n",
        "y = df['quality']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=7)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Create a KNN model\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Fit the model to the training data\n",
        "knn_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = knn_model.predict(X_test_scaled)\n",
        "\n",
        "# Reverse map predicted values to original labels\n",
        "y_pred_original = pd.Series(y_pred).map({v: k for k, v in y_mapping.items()})\n",
        "\n",
        "# Print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred_original)\n",
        "print(f\"Accuracy Percentage: {accuracy * 100}\\n\\n\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AU7hgHhuWos",
        "outputId": "396697a6-02ca-4d80-ca03-6be247298f6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading CSV file: Error tokenizing data. C error: Expected 1 fields in line 4, saw 3\n",
            "\n",
            "Accuracy Percentage: 58.75\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LeBugooNo8iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Try to read the CSV file\n",
        "try:\n",
        "    df = pd.read_csv(\"dataset.csv\", encoding='latin1')\n",
        "    print(\"CSV file read successfully.\")\n",
        "except pd.errors.ParserError as e:\n",
        "    print(f\"Error reading CSV file: {e}\")\n",
        "    # Handle the error or exit the script\n",
        "\n",
        "# Assuming 'quality' is the target variable\n",
        "# Map target variable to start from 0\n",
        "y_mapping = {label: idx for idx, label in enumerate(sorted(df['quality'].unique()))}\n",
        "df['quality'] = df['quality'].map(y_mapping)\n",
        "\n",
        "# Split the data into features (X) and target variable (y)\n",
        "X = df.drop('quality', axis=1)\n",
        "y = df['quality']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=7)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Create an SVM model\n",
        "svm_model = SVC(kernel='rbf', C=1.0, random_state=7)\n",
        "\n",
        "# Fit the model to the training data\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = svm_model.predict(X_test_scaled)\n",
        "\n",
        "# Reverse map predicted values to original labels\n",
        "y_pred_original = pd.Series(y_pred).map({v: k for k, v in y_mapping.items()})\n",
        "\n",
        "# Print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred_original)\n",
        "print(f\"Accuracy Percentage: {accuracy * 100}\\n\\n\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YL0JYEzvSoR",
        "outputId": "f8b94317-6c22-42cd-f11a-030906938e41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading CSV file: Error tokenizing data. C error: Expected 1 fields in line 4, saw 3\n",
            "\n",
            "Accuracy Percentage: 61.04166666666667\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Try to read the CSV file\n",
        "try:\n",
        "    df = pd.read_csv(\"dataset.csv\", encoding='latin1')\n",
        "    print(\"CSV file read successfully.\")\n",
        "except pd.errors.ParserError as e:\n",
        "    print(f\"Error reading CSV file: {e}\")\n",
        "    # Handle the error or exit the script\n",
        "\n",
        "# Assuming 'quality' is the target variable\n",
        "# Map target variable to start from 0\n",
        "y_mapping = {label: idx for idx, label in enumerate(sorted(df['quality'].unique()))}\n",
        "df['quality'] = df['quality'].map(y_mapping)\n",
        "\n",
        "# Split the data into features (X) and target variable (y)\n",
        "X = df.drop('quality', axis=1)\n",
        "y = df['quality']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=7)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Create a Logistic Regression model\n",
        "logistic_model = LogisticRegression(random_state=7)\n",
        "\n",
        "# Fit the model to the training data\n",
        "logistic_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = logistic_model.predict(X_test_scaled)\n",
        "\n",
        "# Reverse map predicted values to original labels\n",
        "y_pred_original = pd.Series(y_pred).map({v: k for k, v in y_mapping.items()})\n",
        "\n",
        "# Print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred_original)\n",
        "print(f\"Accuracy Percentage: {accuracy * 100}\\n\\n\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m00B0qowveGz",
        "outputId": "6c8bacda-aa2b-4984-ae90-7f17f0741adb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading CSV file: Error tokenizing data. C error: Expected 1 fields in line 4, saw 3\n",
            "\n",
            "Accuracy Percentage: 57.70833333333333\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}